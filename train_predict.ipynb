{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree? robust with noise (especially if pruned), can handle irrelevant data\n",
    "# Naive bayes? not too good because of independence assumption\n",
    "# SVM? widely used, need to find the best kernel\n",
    "# nearest neighbors? data must be scaled, not too good with irrelevant features\n",
    "# neural net? requires a lot of time and a lot of data, can deal with irrelevant features, can overfit, local minima issues\n",
    "# ensemble? Ensemble classifiers combine the predictions of multiple base estimators to improve the accuracy of the predictions. One of the key assumptions that ensemble classifiers make is that the base estimators are built independently (so they are diverse)\n",
    "\n",
    "# decision tree, svm, nearest neigh, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   congress  bill sponsor_party sponsor_state  cosponsors  r_cosponsors  \\\n",
      "0       113     1             R            MI           0             0   \n",
      "1       113     2             R            NE          15            15   \n",
      "2       113     3             R            NE         134           132   \n",
      "3       113     4             R            MI           4             4   \n",
      "4       113     5             R            MN          12            12   \n",
      "\n",
      "   d_cosponsors                       subject  withdrawn_cosponsors  \\\n",
      "0             0                      Taxation                     0   \n",
      "1             0                        Energy                     0   \n",
      "2             2                        Energy                     1   \n",
      "3             0  Economics and Public Finance                     0   \n",
      "4             0                     Education                     0   \n",
      "\n",
      "   committees  subcommittees  actions  summary_words  \n",
      "0           1              0        1           2854  \n",
      "1           5              2       24           9938  \n",
      "2           3              4       59            502  \n",
      "3           9              1       26           7709  \n",
      "4           3              0       64           7303  \n"
     ]
    }
   ],
   "source": [
    "# get clean data\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.decomposition\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# need to pip install import_ipynb\n",
    "import import_ipynb\n",
    "from data_preperation import features, labels\n",
    "\n",
    "\n",
    "# at this point, data should be clean \n",
    "print(features.head())\n",
    "#print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>bill</th>\n",
       "      <th>sponsor_party</th>\n",
       "      <th>sponsor_state</th>\n",
       "      <th>cosponsors</th>\n",
       "      <th>r_cosponsors</th>\n",
       "      <th>d_cosponsors</th>\n",
       "      <th>subject</th>\n",
       "      <th>withdrawn_cosponsors</th>\n",
       "      <th>committees</th>\n",
       "      <th>subcommittees</th>\n",
       "      <th>actions</th>\n",
       "      <th>summary_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>134</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress  bill  sponsor_party  sponsor_state  cosponsors  r_cosponsors  \\\n",
       "0         0     0              1             24           0             0   \n",
       "1         0     1              1             32          15            15   \n",
       "2         0     2              1             32         134           130   \n",
       "3         0     3              1             24           4             4   \n",
       "4         0     4              1             25          12            12   \n",
       "\n",
       "   d_cosponsors  subject  withdrawn_cosponsors  committees  subcommittees  \\\n",
       "0             0       30                     0           1              0   \n",
       "1             0       11                     0           5              2   \n",
       "2             2       11                     1           3              4   \n",
       "3             0        8                     0           9              1   \n",
       "4             0        9                     0           3              0   \n",
       "\n",
       "   actions  summary_words  \n",
       "0        0            933  \n",
       "1       23           1033  \n",
       "2       54            492  \n",
       "3       25           1020  \n",
       "4       56           1017  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe do PCA?\n",
    "# need to transform categorical data\n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "# 2/3. FIT AND TRANSFORM\n",
    "# use df.apply() to apply le.fit_transform to all columns\n",
    "features = features.apply(le.fit_transform)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit_transform(features)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3816\n",
      "1     184\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 80%/20% split\n",
    "features, labels = resample(features, labels, n_samples=5000)\n",
    "feat_train, feat_test, label_train, label_test = sk.model_selection.train_test_split(features, labels, test_size=0.2)\n",
    "#print(feat_train.columns)\n",
    "#print(label_train.value_counts())\n",
    "#print(type(label_train))\n",
    "#print(type(feat_train))\n",
    "#sm = SMOTE()\n",
    "#feat_train, label_train = sm.fit_sample(feat_train, label_train)\n",
    "#feat_train, label_train = resample(feat_train, label_train, n_samples=5000)\n",
    "#sm = SMOTENC(random_state=42, categorical_features=[18, 19])\n",
    "#feat_train, label_train = SMOTE().fit_resample(feat_train, label_train)\n",
    "#x = np.linspace(label_train)\n",
    "#print(label_train)\n",
    "\n",
    "#y = pd.DataFrame.from_records(label_train)\n",
    "#print(pd.value_counts(y.values.flatten()))\n",
    "#print(y.value_counts())\n",
    "#print(len(feat_train))\n",
    "#pd.value_counts(df.values.flatten())\n",
    "\n",
    "print(label_train.value_counts())\n",
    "#smt = SMOTE(random_state=0)\n",
    "#feat_resampled, label_resampled = smote.fit_sample(feat_train, label_train)\n",
    "\n",
    "#feat_train = pd.DataFrame(feat_resampled, columns=feat_train.columns)\n",
    "#label_train = pd.Series(label_resampled)\n",
    "#print(label_resampled.head())\n",
    "\n",
    "#print(label_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "def decision_tree_no_SMOTE():\n",
    "    print(\"Decision Tree, no SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple decision tree: \", accuracy*100)\n",
    "\n",
    "    # DOING CROSS VALIDATION \n",
    "    #smt = SMOTE()\n",
    "    # outer loop for CV\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision trees manually or using grid search, INNER CV LOOOP\n",
    "    #best_params = find_best_params(feat_train, label_train)\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10]}\n",
    "              #'smt__k_neighbors': list(range(1, 16, 2))\n",
    "\n",
    "\n",
    "    #smt = SMOTE(ratio=.5)\n",
    "    #pipeline = sk.pipeline.Pipeline(steps=[('smt', smt), ('decision_tree', decision_tree)])\n",
    "    #pipeline = Pipeline([('smt', smt), ('decision_tree', decision_tree)])\n",
    "    pipeline = Pipeline([('decision_tree', decision_tree)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"best params: \", grid_search.best_params_)\n",
    "\n",
    "    # make model with the best parameters, inner loop of CV\n",
    "\n",
    "    #decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy', \n",
    "    #                                               splitter=best_params['splitter'], \n",
    "    #                                               max_depth=best_params['max_depth'], \n",
    "    #                                               min_impurity_decrease=best_params['min_impurity_decrease'], \n",
    "    #                                               min_samples_leaf=best_params['min_samples_leaf'], \n",
    "    #                                               min_samples_split=best_params['min_samples_split'])\n",
    "\n",
    "    #decision_tree.fit(feat_train, label_train)\n",
    "    #label_predict = decision_tree.predict(feat_test)\n",
    "    #accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "\n",
    "    # inner & outer l\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nclassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    # This will return a 2D numpy array with one row for each datapoint in the test set and 2 columns. \n",
    "    # Column index 0 is the probability that this datapoint is in class 0, and column index 1 is the \n",
    "    # probability that this datapoint is in class 1.\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    #print(label_test)\n",
    "    #print(proba[:, 1])\n",
    "\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "def decision_tree_SMOTE():\n",
    "    print(\"Decision Tree, SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple decision tree: \", accuracy*100)\n",
    "\n",
    "    # DOING CROSS VALIDATION \n",
    "    smt = SMOTE()\n",
    "    # outer loop for CV\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision trees manually or using grid search, INNER CV LOOOP\n",
    "    #best_params = find_best_params(feat_train, label_train)\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10],\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))}\n",
    "\n",
    "\n",
    "    #smt = SMOTE(ratio=.5)\n",
    "    #pipeline = sk.pipeline.Pipeline(steps=[('smt', smt), ('decision_tree', decision_tree)])\n",
    "    pipeline = Pipeline([('smt', smt), ('decision_tree', decision_tree)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"best params: \", grid_search.best_params_)\n",
    "\n",
    "    # inner & outer l\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nclassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "# TODO: maybe do confusion matrix??? Just to analyze model more, maybe roc curve is enough?\n",
    "# simple with CV:\n",
    "def naive_bayes_no_SMOTE():\n",
    "    print(\"Naive Bayes, no SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "\n",
    "    print(\"simple model Accuracy:\", scores.mean()*100)\n",
    "\n",
    "    #feat_train, feat_test, label_train, label_test = sk.model_selection.train_test_split(features, labels, test_size=0.2)\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    #params = {\n",
    "    #          'smt__k_neighbors': list(range(1, 16, 2))}\n",
    "\n",
    "\n",
    "    #smt = SMOTE()\n",
    "    #pipeline = Pipeline([('smt', smt), ('naive_bayes', naive_bayes)])\n",
    "    pipeline = Pipeline([('naive_bayes', naive_bayes)])\n",
    "    #grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    #grid_search = GridSearchCV(pipeline, cv=5, scoring='accuracy')\n",
    "    #grid_search.fit(features, labels)\n",
    "    #print(\"best params: \", grid_search.best_params_)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nclassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    # This will return a 2D numpy array with one row for each datapoint in the test set and 2 columns. \n",
    "    # Column index 0 is the probability that this datapoint is in class 0, and column index 1 is the \n",
    "    # probability that this datapoint is in class 1.\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "\n",
    "    #print(label_test)\n",
    "    #print(proba[:, 1])\n",
    "\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "# TODO: maybe do confusion matrix??? Just to analyze model more, maybe roc curve is enough?\n",
    "# simple with CV:\n",
    "def naive_bayes_SMOTE():\n",
    "    print(\"Naive Bayes, SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "\n",
    "    print(\"simple model Accuracy:\", scores.mean()*100)\n",
    "\n",
    "    #feat_train, feat_test, label_train, label_test = sk.model_selection.train_test_split(features, labels, test_size=0.2)\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    params = {\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))}\n",
    "\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('naive_bayes', naive_bayes)])\n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"best params: \", grid_search.best_params_)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nclassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    # This will return a 2D numpy array with one row for each datapoint in the test set and 2 columns. \n",
    "    # Column index 0 is the probability that this datapoint is in class 0, and column index 1 is the \n",
    "    # probability that this datapoint is in class 1.\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "before grid\n",
      "before predict\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "scaler_svm = StandardScaler()\n",
    "pca_redux_svm = PCA()\n",
    "svm_obj = SVC()\n",
    "pipe_svm = Pipeline([('scale', scaler_svm), ('pca', pca_redux_svm), ('svm', svm_obj)])\n",
    "print(\"start\")\n",
    "param_grid = {\n",
    "    'pca__n_components': list(range(5, 13)),\n",
    "    'svm__kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "print(\"before grid\")\n",
    "# Creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "grid_svm = GridSearchCV(pipe_svm, param_grid, cv=5)\n",
    "print(\"before predict\")\n",
    "# Running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "print(\"done\")\n",
    "# Prints the accuracy\n",
    "print(\"Accuracy:\", pred_svm.mean()*100)\n",
    "# The classification report of using an SVM classifier on this data.\n",
    "report_svm = classification_report(labels, pred_svm)\n",
    "print(report_svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'knn__n_neighbors': 14, 'pca__n_components': 12}\n",
      "Accuracy: 96.36674047219316\n"
     ]
    }
   ],
   "source": [
    "# scaling\n",
    "def nearest_neighbors_no_SMOTE():\n",
    "    print(\"scaling...\")\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    #smt = SMOTE()\n",
    "    #pipeline = Pipeline([('smt', smt), ('standard_scaler', standard_scaler), ('pca', pca), ('knn', knn)])\n",
    "    pipeline = Pipeline([('standard_scaler', standard_scaler), ('pca', pca), ('knn', knn)])\n",
    "    #pipeline = sk.pipeline.Pipeline(steps=[('standard_scaler', standard_scaler), ('pca', pca), ('knn', knn)])\n",
    "    print(\"finished scaling.\")\n",
    "    # inner loop\n",
    "    print(\"starting inner loop...\")\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "    #print(\"Accuracy:\", scores.mean()*100)\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2))}\n",
    "        #'smt__k_neighbors': list(range(1, 26, 2))\n",
    "\n",
    "\n",
    "    # param_grid=  {'knn__n_neighbors': [1], 'pca__n_components': [13], 'smt__k_neighbors': [1]}\n",
    "\n",
    "    #param_grid = {\n",
    "    #    'pca__n_components': [12],\n",
    "    #    'knn__n_neighbors': [15]\n",
    "    #}\n",
    "\n",
    "    print(\"starting grid search...\")\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"best params: \", grid_search.best_params_)\n",
    "    #print(\"Accuracy: \", grid_search.best_score_*100)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "\n",
    "    print(\"Accuracy with best params:\", scores.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nclassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "def nearest_neighbors_SMOTE():\n",
    "    print(\"Nearest Neighbors, SMOTE\")\n",
    "    print(\"scaling...\")\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('standard_scaler', standard_scaler), ('pca', pca), ('knn', knn)])\n",
    "    print(\"finished scaling.\")\n",
    "    # inner loop\n",
    "    print(\"starting inner loop...\")\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "    #print(\"Accuracy:\", scores.mean()*100)\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2)),\n",
    "        'smt__k_neighbors': list(range(1, 26, 2))}\n",
    "\n",
    "    print(\"starting grid search...\")\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"best params: \", grid_search.best_params_)\n",
    "    #print(\"Accuracy: \", grid_search.best_score_*100)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "\n",
    "    print(\"Accuracy with best params:\", scores.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nclassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.5493785749753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "scaler_nn = sk.preprocessing.StandardScaler()\n",
    "mlp_nn = MLPClassifier()\n",
    "pipe_nn = sk.pipeline.Pipeline([('scale', scaler_nn), ('nn', mlp_nn)])\n",
    "# Try values of hidden_layer_sizes ranging from (30,) to (60,) by increments of 10.\n",
    "param_grid_nn = {\n",
    "    'nn__hidden_layer_sizes': [(30,),(40,),(50,),(60,)],\n",
    "    'nn__activation': ['logistic', 'tanh', 'relu']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV with 5 fold cross validation to find the best hidden layer size and the best activation function.\n",
    "grid_nn = GridSearchCV(pipe_nn, param_grid_nn, cv=5)\n",
    "# Wrapping the GridSearchCV in a 5-fold cross_val_score.\n",
    "pred_nn = cross_val_score(grid_nn, features, labels, cv=5)\n",
    "# Prints the accuracy of your neural net\n",
    "print(\"Accuracy:\", pred_nn.mean()*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.45805952358423\n",
      "Accuracy: 96.57477086879261\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params_rf = {\"max_depth\": list(range(35,56)), \"min_samples_leaf\": [8,10,12], \"max_features\": ['sqrt','log2']}\n",
    "\n",
    "rf = sklearn.ensemble.RandomForestClassifier()\n",
    "# Using GridSearchCV with a 5-fold CV to tune the hyperparameters to get the best results.\n",
    "grid_search_rf = GridSearchCV(rf, params_rf, cv=5)\n",
    "# Wrapping the GridSearchCV in a cross_val_score with 5-fold CV to report the accuracy of the model.\n",
    "pred_rf = sk.model_selection.cross_val_score(grid_search_rf, features, labels, cv=5)\n",
    "\n",
    "print(\"Accuracy:\", pred_rf.mean()*100)\n",
    "\n",
    "\n",
    "\n",
    "# using ensemble classifiers called boosting on the data.\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "boost_clf = AdaBoostClassifier(n_estimators = 150)\n",
    "\n",
    "# evaluating it's accuracy with a 5-fold-CV.\n",
    "pred_boost = cross_val_score(boost_clf, features, labels, cv=5)\n",
    "\n",
    "print(\"Accuracy:\", pred_boost.mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree, no SMOTE\n",
      "Accuracy of simple decision tree:  96.3\n",
      "best params:  {'decision_tree__max_depth': 5, 'decision_tree__max_features': 10, 'decision_tree__min_samples_leaf': 15}\n",
      "Accuracy of decision tree with the best parameters and CV:  96.85963739963739\n",
      "confusion matrix: \n",
      " [[4713   70]\n",
      " [ 115  102]]\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4783\n",
      "           1       0.59      0.47      0.52       217\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.78      0.73      0.75      5000\n",
      "weighted avg       0.96      0.96      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.7179655918021999\n",
      "Naive Bayes, no SMOTE\n",
      "simple model Accuracy: 93.47978407913632\n",
      "Accuracy of decision tree with the best parameters and CV:  93.39973485973486\n",
      "confusion matrix: \n",
      " [[4522  261]\n",
      " [  65  152]]\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      4783\n",
      "           1       0.37      0.70      0.48       217\n",
      "\n",
      "    accuracy                           0.93      5000\n",
      "   macro avg       0.68      0.82      0.72      5000\n",
      "weighted avg       0.96      0.93      0.94      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.9638055842812823\n",
      "scaling...\n",
      "Accuracy of simple KNN:  96.5\n",
      "finished scaling.\n",
      "starting inner loop...\n",
      "starting grid search...\n",
      "best params:  {'knn__n_neighbors': 11, 'pca__n_components': 11}\n"
     ]
    }
   ],
   "source": [
    "decision_tree_no_SMOTE()\n",
    "naive_bayes_no_SMOTE()\n",
    "nearest_neighbors_no_SMOTE()\n",
    "\n",
    "decision_tree_SMOTE()\n",
    "naive_bayes_SMOTE()\n",
    "nearest_neighbors_SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
