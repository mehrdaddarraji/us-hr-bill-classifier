{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree? robust with noise (especially if pruned), can handle irrelevant data\n",
    "# Naive bayes? not too good because of independence assumption\n",
    "# SVM? widely used, need to find the best kernel\n",
    "# nearest neighbors? data must be scaled, not too good with irrelevant features\n",
    "# neural net? requires a lot of time and a lot of data, can deal with irrelevant features, can overfit, local minima issues\n",
    "# ensemble? ensemble classifiers combine the predictions of multiple base estimators to improve the accuracy of the predictions. One of the key assumptions that ensemble classifiers make is that the base estimators are built independently (so they are diverse)\n",
    "\n",
    "# decision tree, svm, nearest neigh, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   congress  bill sponsor_party sponsor_state  cosponsors  r_cosponsors  \\\n",
      "0       113     1             R            MI           0             0   \n",
      "1       113     2             R            NE          15            15   \n",
      "2       113     3             R            NE         134           132   \n",
      "3       113     4             R            MI           4             4   \n",
      "4       113     5             R            MN          12            12   \n",
      "\n",
      "   d_cosponsors                       subject  withdrawn_cosponsors  \\\n",
      "0             0                      Taxation                     0   \n",
      "1             0                        Energy                     0   \n",
      "2             2                        Energy                     1   \n",
      "3             0  Economics and Public Finance                     0   \n",
      "4             0                     Education                     0   \n",
      "\n",
      "   committees  subcommittees  actions  summary_words  \n",
      "0           1              0        1           2854  \n",
      "1           5              2       24           9938  \n",
      "2           3              4       59            502  \n",
      "3           9              1       26           7709  \n",
      "4           3              0       64           7303  \n"
     ]
    }
   ],
   "source": [
    "# get clean data\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.decomposition\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# need to pip install import_ipynb\n",
    "import import_ipynb\n",
    "# need to pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from data_preperation import features, labels\n",
    "\n",
    "# at this point, data should be clean \n",
    "print(features.head())\n",
    "#print(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>bill</th>\n",
       "      <th>sponsor_party</th>\n",
       "      <th>sponsor_state</th>\n",
       "      <th>cosponsors</th>\n",
       "      <th>r_cosponsors</th>\n",
       "      <th>d_cosponsors</th>\n",
       "      <th>subject</th>\n",
       "      <th>withdrawn_cosponsors</th>\n",
       "      <th>committees</th>\n",
       "      <th>subcommittees</th>\n",
       "      <th>actions</th>\n",
       "      <th>summary_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>134</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress  bill  sponsor_party  sponsor_state  cosponsors  r_cosponsors  \\\n",
       "0         0     0              1             24           0             0   \n",
       "1         0     1              1             32          15            15   \n",
       "2         0     2              1             32         134           130   \n",
       "3         0     3              1             24           4             4   \n",
       "4         0     4              1             25          12            12   \n",
       "\n",
       "   d_cosponsors  subject  withdrawn_cosponsors  committees  subcommittees  \\\n",
       "0             0       30                     0           1              0   \n",
       "1             0       11                     0           5              2   \n",
       "2             2       11                     1           3              4   \n",
       "3             0        8                     0           9              1   \n",
       "4             0        9                     0           3              0   \n",
       "\n",
       "   actions  summary_words  \n",
       "0        0            933  \n",
       "1       23           1033  \n",
       "2       54            492  \n",
       "3       25           1020  \n",
       "4       56           1017  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe do PCA?\n",
    "# need to transform categorical data\n",
    "# 1. INSTANTIATE\n",
    "# encode labels with value between 0 and n_classes-1.\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "\n",
    "# 2/3. FIT AND TRANSFORM\n",
    "# use df.apply() to apply le.fit_transform to all columns\n",
    "features = features.apply(le.fit_transform)\n",
    "\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# 2. FIT\n",
    "enc.fit_transform(features)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3792\n",
      "1     208\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 80%/20% split of the actual data\n",
    "features, labels = resample(features, labels, n_samples=5000)\n",
    "feat_train, feat_test, label_train, label_test = sk.model_selection.train_test_split(features, labels, test_size=0.2)\n",
    "\n",
    "print(label_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree, no SMOTE\n",
      "Accuracy of decision tree:  95.8\n",
      "Best params:  {'decision_tree__max_depth': 20, 'decision_tree__max_features': 10, 'decision_tree__min_samples_leaf': 20}\n",
      "Accuracy of decision tree with the best parameters and CV:  95.98023836023837\n",
      "Confusion matrix: \n",
      " [[4661   78]\n",
      " [ 128  133]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      4739\n",
      "           1       0.63      0.51      0.56       261\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.80      0.75      0.77      5000\n",
      "weighted avg       0.96      0.96      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.7997051264170868\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier without SMOTE\n",
    "def decision_tree_no_SMOTE():\n",
    "    print(\"Decision Tree, no SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of decision tree: \", accuracy*100)\n",
    "\n",
    "    # DOING CROSS VALIDATION \n",
    "    # outer loop for CV\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision trees manually or using grid search, INNER CV LOOOP\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10]\n",
    "             }\n",
    "\n",
    "    pipeline = Pipeline([('decision_tree', decision_tree)])\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # inner & outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "    # prints the accuracy of your decision tree\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Decision Tree classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    # This will return a 2D numpy array with one row for each datapoint in the test set and 2 columns. \n",
    "    # Column index 0 is the probability that this datapoint is in class 0, and column index 1 is the \n",
    "    # probability that this datapoint is in class 1.\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree, SMOTE\n",
      "Accuracy of decision tree:  95.5\n",
      "Best params:  {'decision_tree__max_depth': 15, 'decision_tree__max_features': 10, 'decision_tree__min_samples_leaf': 5, 'smt__k_neighbors': 5}\n",
      "Accuracy of decision tree with the best parameters and CV:  96.18027832027832\n",
      "Confusion matrix: \n",
      " [[4604  135]\n",
      " [  53  208]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      4739\n",
      "           1       0.61      0.80      0.69       261\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.80      0.88      0.83      5000\n",
      "weighted avg       0.97      0.96      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.7614412942559423\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Decision Tree Classifier with SMOTE\n",
    "def decision_tree_SMOTE():\n",
    "    print(\"Decision Tree, SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of decision tree: \", accuracy*100)\n",
    "\n",
    "    # DOING CROSS VALIDATION \n",
    "    smt = SMOTE()\n",
    "    # outer loop for CV\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision trees manually or using grid search, INNER CV LOOOP\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10],\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))\n",
    "             }\n",
    "\n",
    "    pipeline = Pipeline([('smt', smt), ('decision_tree', decision_tree)])\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # inner & outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "    # prints the accuracy of your decision tree\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Decision Tree classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, no SMOTE\n",
      "Accuracy of simple Naive Bayes: 92.60071408285633\n",
      "Accuracy of naive bayes with the best parameters and CV:  92.7003172003172\n",
      "Confusion matrix: \n",
      " [[4459  280]\n",
      " [  90  171]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      4739\n",
      "           1       0.38      0.66      0.48       261\n",
      "\n",
      "    accuracy                           0.93      5000\n",
      "   macro avg       0.68      0.80      0.72      5000\n",
      "weighted avg       0.95      0.93      0.94      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.9296288179155626\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier without SMOTE\n",
    "# TODO: maybe do confusion matrix??? Just to analyze model more, maybe roc curve is enough?\n",
    "# simple with CV:\n",
    "def naive_bayes_no_SMOTE():\n",
    "    print(\"Naive Bayes, no SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    print(\"Accuracy of simple Naive Bayes:\", scores.mean()*100)\n",
    "\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "\n",
    "    pipeline = Pipeline([('naive_bayes', naive_bayes)])\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "    # prints the accuracy of your naive bayes\n",
    "    print(\"Accuracy of naive bayes with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Naive Bayes classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    # This will return a 2D numpy array with one row for each datapoint in the test set and 2 columns. \n",
    "    # Column index 0 is the probability that this datapoint is in class 0, and column index 1 is the \n",
    "    # probability that this datapoint is in class 1.\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes, SMOTE\n",
      "Accuracy of simple Naive Bayes:  92.60071408285633\n",
      "Best params:  {'smt__k_neighbors': 1}\n",
      "Accuracy of naive bayes with the best parameters and CV:  92.7003172003172\n",
      "Confusion matrix: \n",
      " [[4459  280]\n",
      " [  90  171]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      4739\n",
      "           1       0.38      0.66      0.48       261\n",
      "\n",
      "    accuracy                           0.93      5000\n",
      "   macro avg       0.68      0.80      0.72      5000\n",
      "weighted avg       0.95      0.93      0.94      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.9296288179155626\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier with SMOTE\n",
    "def naive_bayes_SMOTE():\n",
    "    print(\"Naive Bayes, SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    \n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    print(\"Accuracy of simple Naive Bayes: \", scores.mean()*100)\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    params = {\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))\n",
    "            }\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('naive_bayes', naive_bayes)]) \n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    \n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "    # prints the accuracy of your naive bayes\n",
    "    print(\"Accuracy of naive bayes with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Naive Bayes classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    # This will return a 2D numpy array with one row for each datapoint in the test set and 2 columns. \n",
    "    # Column index 0 is the probability that this datapoint is in class 0, and column index 1 is the \n",
    "    # probability that this datapoint is in class 1.\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple neural network:  95.6\n",
      "Best params:  {'pca__n_components': 11, 'svm__kernel': 'linear'}\n",
      "Accuracy of svm with the best parameters and CV:  96.68015884015884\n",
      "Confusion matrix: \n",
      " [[4706   33]\n",
      " [ 135  126]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4739\n",
      "           1       0.79      0.48      0.60       261\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.88      0.74      0.79      5000\n",
      "weighted avg       0.96      0.97      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.7141419776453946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Support Vector Machines(SVM) Classifier without SMOTE\n",
    "def svm_no_SMOTE():\n",
    "    scaler_svm = StandardScaler()\n",
    "    # scaling\n",
    "    features = scaler_svm.fit_transform(features)\n",
    "    pca_redux_svm = PCA()\n",
    "    svm_obj = SVC(probability=True)\n",
    "    sm = SMOTE()\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train) # train the model\n",
    "    label_predict = svm_obj.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_svm = Pipeline([('pca', pca_redux_svm), ('svm', svm_obj)])\n",
    "    \n",
    "    # parameter-grid\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(3, 13)),\n",
    "        'svm__kernel': ['linear', 'rbf','poly']\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_svm = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_svm.fit(features, labels)\n",
    "\n",
    "    print(\"Best params: \", grid_svm.best_params_)\n",
    "\n",
    "    pred_svm = cross_val_score(grid_svm, features, labels, cv=5)\n",
    "    # prints the accuracy of your neural net\n",
    "    print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, pred_svm)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using an SVM classifier on this data.\n",
    "    report_svm = classification_report(labels, pred_svm)\n",
    "    print(\"\\nClassification report:\\n\", report_svm)\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)\n",
    "    proba = svm_obj.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple neural network:  95.6\n",
      "Best params:  {'pca__n_components': 9, 'smote__k_neighbors': 1, 'svm__kernel': 'rbf'}\n",
      "Accuracy of svm with the best parameters and CV:  94.8601578001578\n",
      "Confusion matrix: \n",
      " [[4514  225]\n",
      " [  26  235]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      4739\n",
      "           1       0.51      0.90      0.65       261\n",
      "\n",
      "    accuracy                           0.95      5000\n",
      "   macro avg       0.75      0.93      0.81      5000\n",
      "weighted avg       0.97      0.95      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.717160447092108\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Support Vector Machines(SVM) Classifier with SMOTE\n",
    "def svm_SMOTE():\n",
    "    scaler_svm = StandardScaler()\n",
    "    # scaling\n",
    "    features = scaler_svm.fit_transform(features)\n",
    "    pca_redux_svm = PCA()\n",
    "    svm_obj = SVC(probability=True)\n",
    "    sm = SMOTE()\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = svm_obj.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_svm = Pipeline([('smote', sm), ('pca', pca_redux_svm), ('svm', svm_obj)])\n",
    "\n",
    "    # parameter-grid\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(3, 13)),\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'smote__k_neighbors': list(range(1, 10, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_svm = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_svm.fit(features, labels)\n",
    "    print(\"Best params: \", grid_svm.best_params_)\n",
    "\n",
    "    pred_svm = cross_val_score(grid_svm, features, labels, cv=5)\n",
    "    # prints the accuracy of your neural net\n",
    "    print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, pred_svm)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using an SVM classifier on this data.\n",
    "    report_svm = classification_report(labels, pred_svm)\n",
    "    print(\"\\nClassification report:\\n\", report_svm)\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)\n",
    "    proba = svm_obj.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple KNN:  94.8\n",
      "Best params:  {'knn__n_neighbors': 1, 'pca__n_components': 12}\n",
      "Accuracy of knn with the best parameters and CV:  96.35995855995854\n",
      "Confusion matrix: \n",
      " [[4650   89]\n",
      " [  93  168]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      4739\n",
      "           1       0.65      0.64      0.65       261\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.82      0.81      0.81      5000\n",
      "weighted avg       0.96      0.96      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.6975553386065232\n"
     ]
    }
   ],
   "source": [
    "# Nearest Neighbors Classifier without SMOTE\n",
    "def nearest_neighbors_no_SMOTE():\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    # scaling\n",
    "    features = standard_scaler.fit_transform(features)\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "    pipeline = Pipeline([('pca', pca), ('knn', knn)])\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    # Prints the accuracy of your knn\n",
    "    print(\"Accuracy of knn with the best parameters and CV: \", scores.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a nearest neighbor classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple KNN:  94.8\n",
      "Best params:  {'knn__n_neighbors': 1, 'pca__n_components': 13, 'smt__k_neighbors': 1}\n",
      "Accuracy of knn with the best parameters and CV:  96.36001858001858\n",
      "Confusion matrix: \n",
      " [[4641   98]\n",
      " [  85  176]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      4739\n",
      "           1       0.64      0.67      0.66       261\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.81      0.83      0.82      5000\n",
      "weighted avg       0.96      0.96      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.6975553386065232\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Nearest Neighbors Classifier with SMOTE\n",
    "def nearest_neighbors_SMOTE():\n",
    "\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    # scaling\n",
    "    features = standard_scaler.fit_transform(features)\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('pca', pca), ('knn', knn)])\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "    \n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2)),\n",
    "        'smt__k_neighbors': list(range(1, 26, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    # Prints the accuracy of your knn\n",
    "    print(\"Accuracy of knn with the best parameters and CV: \", scores.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a nearest neighbor classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple neural network:  94.89999999999999\n",
      "Best params:  {'nn__activation': 'tanh', 'nn__hidden_layer_sizes': (40,)}\n",
      "Accuracy of neural network with the best parameters and CV:  96.74005858005857\n",
      "Confusion matrix: \n",
      " [[4676   63]\n",
      " [  91  170]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4739\n",
      "           1       0.73      0.65      0.69       261\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.86      0.82      0.84      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.9609093263732542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Neural Network Classifier without SMOTE\n",
    "def neural_network_no_SMOTE():\n",
    "    scaler_nn = StandardScaler()\n",
    "    mlp_nn = MLPClassifier()\n",
    "    # scaling\n",
    "    features = scaler_nn.fit_transform(features)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = mlp_nn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_nn = Pipeline([('nn', mlp_nn)])\n",
    "    # Try values of hidden_layer_sizes ranging from (30,) to (60,) by increments of 10.\n",
    "    param_grid_nn = {\n",
    "        'nn__hidden_layer_sizes': [(30,),(40,),(50,),(60,)],\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu']\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV with 5 fold cross validation to find the best hidden layer size and the best activation function.\n",
    "    grid_nn = GridSearchCV(pipe_nn, param_grid_nn, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_nn.fit(features, labels)\n",
    "    print(\"Best params: \", grid_nn.best_params_)\n",
    "    # Wrapping the GridSearchCV in a 5-fold cross_val_score.\n",
    "    pred_nn = cross_val_score(grid_nn, features, labels, cv=5)\n",
    "    # Prints the accuracy of your neural net\n",
    "    print(\"Accuracy of neural network with the best parameters and CV: \", pred_nn.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = cross_val_predict(grid_nn, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "    \n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)\n",
    "    proba = mlp_nn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple neural network:  96.1\n",
      "Best params:  {'nn__activation': 'tanh', 'nn__hidden_layer_sizes': (50,), 'smt__k_neighbors': 3}\n",
      "Accuracy of neural network with the best parameters and CV:  96.08019832019832\n",
      "Confusion matrix: \n",
      " [[4601  138]\n",
      " [  39  222]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      4739\n",
      "           1       0.62      0.85      0.71       261\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.80      0.91      0.85      5000\n",
      "weighted avg       0.97      0.96      0.97      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.939112589906557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Neural Network Classifier with SMOTE\n",
    "def neural_network_SMOTE():\n",
    "    scaler_nn = StandardScaler()\n",
    "    mlp_nn = MLPClassifier()\n",
    "    smt = SMOTE()\n",
    "    # scaling\n",
    "    features = scaler_nn.fit_transform(features)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = mlp_nn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_nn = Pipeline([('smt', smt), ('nn', mlp_nn)])\n",
    "    # Try values of hidden_layer_sizes ranging from (30,) to (60,) by increments of 10.\n",
    "    param_grid_nn = {\n",
    "        'nn__hidden_layer_sizes': [(30,),(40,),(50,),(60,)],\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'smt__k_neighbors': list(range(1, 18, 2))\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV with 5 fold cross validation to find the best hidden layer size and the best activation function.\n",
    "    grid_nn = GridSearchCV(pipe_nn, param_grid_nn, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_nn.fit(features, labels)\n",
    "    print(\"Best params: \", grid_nn.best_params_)\n",
    "    # Wrapping the GridSearchCV in a 5-fold cross_val_score.\n",
    "    pred_nn = cross_val_score(grid_nn, features, labels, cv=5)\n",
    "    # Prints the accuracy of your neural net\n",
    "    print(\"Accuracy of neural network with the best parameters and CV: \", pred_nn.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = cross_val_predict(grid_nn, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)\n",
    "    proba = mlp_nn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple ensemble:  96.0\n",
      "Best params:  {'rf__max_depth': 40, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 8}\n",
      "Accuracy of ensemble with the best parameters and CV:  96.53987871987871\n",
      "Confusion matrix: \n",
      " [[4706   33]\n",
      " [ 136  125]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4739\n",
      "           1       0.79      0.48      0.60       261\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.88      0.74      0.79      5000\n",
      "weighted avg       0.96      0.97      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.9715885318084915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# using RandomForestClassifier\n",
    "# Ensemble Classifier without SMOTE\n",
    "def ensemble_no_SMOTE():\n",
    "    rf = sklearn.ensemble.RandomForestClassifier()\n",
    "    \n",
    "    rf.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = rf.predict(feat_test)  # predict labels of test data\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple ensemble: \", accuracy*100)\n",
    "    \n",
    "    pipe_ensemble = Pipeline([('rf', rf)])\n",
    "    # parameter-grid\n",
    "    params_rf = {'rf__max_depth': list(range(35,56)), \n",
    "                 'rf__min_samples_leaf': [8,10,12], \n",
    "                 'rf__max_features': ['sqrt','log2']\n",
    "    }\n",
    "\n",
    "\n",
    "    # Using GridSearchCV with a 5-fold CV to tune the hyperparameters to get the best results.\n",
    "    grid_search_rf = GridSearchCV(pipe_ensemble, params_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_search_rf.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search_rf.best_params_)\n",
    "    # Wrapping the GridSearchCV in a cross_val_score with 5-fold CV to report the accuracy of the model.\n",
    "    pred_rf = sk.model_selection.cross_val_score(grid_search_rf, features, labels, cv=5)\n",
    "    print(\"Accuracy of ensemble with the best parameters and CV: \", pred_rf.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search_rf, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    rf.fit(feat_train, label_train)\n",
    "    proba = rf.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of simple ensemble:  96.0\n",
      "Best params:  {'rf__max_depth': 46, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 8, 'smt__k_neighbors': 1}\n",
      "Accuracy of ensemble with the best parameters and CV:  95.48011824011824\n",
      "Confusion matrix: \n",
      " [[4569  170]\n",
      " [  44  217]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98      4739\n",
      "           1       0.56      0.83      0.67       261\n",
      "\n",
      "    accuracy                           0.96      5000\n",
      "   macro avg       0.78      0.90      0.82      5000\n",
      "weighted avg       0.97      0.96      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.9826662150584766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# using RandomForestClassifier\n",
    "# Ensemble Classifier with SMOTE\n",
    "def ensemble_SMOTE():\n",
    "    rf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "    rf.fit(feat_train, label_train) # train the model\n",
    "    label_predict = rf.predict(feat_test) # predict labels of test data\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple ensemble: \", accuracy*100)\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipe_ensemble = Pipeline([('smt', smt), ('rf', rf)])\n",
    "    # parameter-grid\n",
    "    params_rf = {'rf__max_depth': list(range(35,56)), \n",
    "                 'rf__min_samples_leaf': [8,10,12], \n",
    "                 'rf__max_features': ['sqrt','log2'],\n",
    "                 'smt__k_neighbors': list(range(1, 16, 2)),\n",
    "    }\n",
    "\n",
    "    # Using GridSearchCV with a 5-fold CV to tune the hyperparameters to get the best results.\n",
    "    grid_search_rf = GridSearchCV(pipe_ensemble, params_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "    grid_search_rf.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search_rf.best_params_)\n",
    "    # Wrapping the GridSearchCV in a cross_val_score with 5-fold CV to report the accuracy of the model.\n",
    "    pred_rf = sk.model_selection.cross_val_score(grid_search_rf, features, labels, cv=5)\n",
    "    print(\"Accuracy of ensemble with the best parameters and CV: \", pred_rf.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search_rf, features, labels, cv=5)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    rf.fit(feat_train, label_train)\n",
    "    proba = rf.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of classifiers without SMOTE\n",
    "decision_tree_no_SMOTE()\n",
    "naive_bayes_no_SMOTE()\n",
    "svm_no_SMOTE()\n",
    "nearest_neighbors_no_SMOTE()\n",
    "neural_network_no_SMOTE()\n",
    "ensemble_no_SMOTE()\n",
    "\n",
    "# set of classifiers with SMOTE\n",
    "decision_tree_SMOTE()\n",
    "naive_bayes_SMOTE()\n",
    "svm_SMOTE()\n",
    "nearest_neighbors_SMOTE()\n",
    "neural_network_SMOTE()\n",
    "ensemble_SMOTE()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
