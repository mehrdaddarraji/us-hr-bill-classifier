{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   congress  bill sponsor_party sponsor_state  cosponsors  r_cosponsors  \\\n",
      "0       113     1             R            MI           0             0   \n",
      "1       113     2             R            NE          15            15   \n",
      "2       113     3             R            NE         134           132   \n",
      "3       113     4             R            MI           4             4   \n",
      "4       113     5             R            MN          12            12   \n",
      "\n",
      "   d_cosponsors                       subject  withdrawn_cosponsors  \\\n",
      "0             0                      Taxation                     0   \n",
      "1             0                        Energy                     0   \n",
      "2             2                        Energy                     1   \n",
      "3             0  Economics and Public Finance                     0   \n",
      "4             0                     Education                     0   \n",
      "\n",
      "   committees  subcommittees  actions  summary_words  \n",
      "0           1              0        1           2854  \n",
      "1           5              2       24           9938  \n",
      "2           3              4       59            502  \n",
      "3           9              1       26           7709  \n",
      "4           3              0       64           7303  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.decomposition\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# need to pip install import_ipynb\n",
    "import import_ipynb\n",
    "# need to pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from data_preperation import features, labels\n",
    "\n",
    "# at this point, data should be clean \n",
    "print(features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>congress</th>\n",
       "      <th>bill</th>\n",
       "      <th>sponsor_party</th>\n",
       "      <th>sponsor_state</th>\n",
       "      <th>cosponsors</th>\n",
       "      <th>r_cosponsors</th>\n",
       "      <th>d_cosponsors</th>\n",
       "      <th>subject</th>\n",
       "      <th>withdrawn_cosponsors</th>\n",
       "      <th>committees</th>\n",
       "      <th>subcommittees</th>\n",
       "      <th>actions</th>\n",
       "      <th>summary_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>134</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   congress  bill  sponsor_party  sponsor_state  cosponsors  r_cosponsors  \\\n",
       "0         0     0              1             24           0             0   \n",
       "1         0     1              1             32          15            15   \n",
       "2         0     2              1             32         134           130   \n",
       "3         0     3              1             24           4             4   \n",
       "4         0     4              1             25          12            12   \n",
       "\n",
       "   d_cosponsors  subject  withdrawn_cosponsors  committees  subcommittees  \\\n",
       "0             0       30                     0           1              0   \n",
       "1             0       11                     0           5              2   \n",
       "2             2       11                     1           3              4   \n",
       "3             0        8                     0           9              1   \n",
       "4             0        9                     0           3              0   \n",
       "\n",
       "   actions  summary_words  \n",
       "0        0            933  \n",
       "1       23           1033  \n",
       "2       54            492  \n",
       "3       25           1020  \n",
       "4       56           1017  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit and transform to all columns\n",
    "features = features.apply(le.fit_transform)\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# fit\n",
    "enc.fit_transform(features)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3816\n",
      "1     184\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 80%/20% split of the actual data\n",
    "features, labels = resample(features, labels, n_samples=5000)\n",
    "feat_train, feat_test, label_train, label_test = sk.model_selection.train_test_split(features, labels, test_size=0.2)\n",
    "print(label_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier without SMOTE\n",
    "def decision_tree_no_SMOTE(features):\n",
    "    print(\"Decision Tree, no SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of decision tree: \", accuracy*100)\n",
    "\n",
    "    # DOING CROSS VALIDATION \n",
    "    # outer loop for CV\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision tree\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10]}\n",
    "    \n",
    "    pipeline = Pipeline([('decision_tree', decision_tree)])\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # inner & outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "    # prints the accuracy of your decision tree\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    # running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Decision Tree classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier with SMOTE\n",
    "def decision_tree_SMOTE(features):\n",
    "    print(\"Decision Tree, SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of decision tree: \", accuracy*100)\n",
    "\n",
    "    smt = SMOTE()\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision tree\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10],\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))\n",
    "             }\n",
    "\n",
    "    pipeline = Pipeline([('smt', smt), ('decision_tree', decision_tree)])\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # inner & outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Decision Tree classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier without SMOTE\n",
    "# simple with CV:\n",
    "def naive_bayes_no_SMOTE(features):\n",
    "    print(\"Naive Bayes, no SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    print(\"Accuracy of simple Naive Bayes:\", scores.mean()*100)\n",
    "\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "\n",
    "    pipeline = Pipeline([('naive_bayes', naive_bayes)])\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    \n",
    "    # outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "    # prints the accuracy of your naive bayes\n",
    "    print(\"Accuracy of naive bayes with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Naive Bayes classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "    \n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier with SMOTE\n",
    "def naive_bayes_SMOTE(features):\n",
    "    print(\"Naive Bayes, SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    \n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    print(\"Accuracy of simple Naive Bayes: \", scores.mean()*100)\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    params = {\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))\n",
    "            }\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('naive_bayes', naive_bayes)]) \n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "        \n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    \n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    \n",
    "    # outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "    # prints the accuracy of your naive bayes\n",
    "    print(\"Accuracy of naive bayes with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "    \n",
    "    # Model Analysis: Confusion Matrix\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Naive Bayes classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "    \n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Support Vector Machines(SVM) Classifier without SMOTE\n",
    "def svm_no_SMOTE(features):\n",
    "    scaler_svm = StandardScaler()\n",
    "    # scaling\n",
    "    features = scaler_svm.fit_transform(features)\n",
    "    pca_redux_svm = PCA()\n",
    "    svm_obj = SVC(probability=True)\n",
    "    sm = SMOTE()\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train) # train the model\n",
    "    label_predict = svm_obj.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_svm = Pipeline([('pca', pca_redux_svm), ('svm', svm_obj)])\n",
    "    \n",
    "    # parameter-grid\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(3, 13)),\n",
    "        'svm__kernel': ['linear', 'rbf','poly']\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_svm = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_svm.fit(features, labels)\n",
    "\n",
    "    print(\"Best params: \", grid_svm.best_params_)\n",
    "\n",
    "    pred_svm = cross_val_score(grid_svm, features, labels, cv=5)\n",
    "    # prints the accuracy of your neural net\n",
    "    print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, pred_svm)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using an SVM classifier on this data.\n",
    "    report_svm = classification_report(labels, pred_svm)\n",
    "    print(\"\\nClassification report:\\n\", report_svm)\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)\n",
    "    proba = svm_obj.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Support Vector Machines(SVM) Classifier with SMOTE\n",
    "def svm_SMOTE(features):\n",
    "    scaler_svm = StandardScaler()\n",
    "    # scaling\n",
    "    features = scaler_svm.fit_transform(features)\n",
    "    pca_redux_svm = PCA()\n",
    "    svm_obj = SVC(probability=True)\n",
    "    sm = SMOTE()\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = svm_obj.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_svm = Pipeline([('smote', sm), ('pca', pca_redux_svm), ('svm', svm_obj)])\n",
    "\n",
    "    # parameter-grid\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(3, 13)),\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'smote__k_neighbors': list(range(1, 10, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_svm = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_svm.fit(features, labels)\n",
    "    print(\"Best params: \", grid_svm.best_params_)\n",
    "\n",
    "    pred_svm = cross_val_score(grid_svm, features, labels, cv=5)\n",
    "    # prints the accuracy of your neural net\n",
    "    print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, pred_svm)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using an SVM classifier on this data.\n",
    "    report_svm = classification_report(labels, pred_svm)\n",
    "    print(\"\\nClassification report:\\n\", report_svm)\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)\n",
    "    proba = svm_obj.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbors Classifier without SMOTE\n",
    "def nearest_neighbors_no_SMOTE(features):\n",
    "    print(\"Nearest Neighbors, no SMOTE\")\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    # scaling\n",
    "    features = standard_scaler.fit_transform(features)\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier()\n",
    "    pipeline = Pipeline([('pca', pca), ('knn', knn)])\n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    # Prints the accuracy of your knn\n",
    "    print(\"Accuracy of knn with the best parameters and CV: \", scores.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a nearest neighbor classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Nearest Neighbors Classifier with SMOTE\n",
    "def nearest_neighbors_SMOTE(features):\n",
    "    print(\"Nearest Neighbors, SMOTE\")\n",
    "\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    # scaling\n",
    "    features = standard_scaler.fit_transform(features)\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier()\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('pca', pca), ('knn', knn)])\n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "    \n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2)),\n",
    "        'smt__k_neighbors': list(range(1, 26, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    # Prints the accuracy of your knn\n",
    "    print(\"Accuracy of knn with the best parameters and CV: \", scores.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a nearest neighbor classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Neural Network Classifier without SMOTE\n",
    "def neural_network_no_SMOTE(features):\n",
    "    scaler_nn = StandardScaler()\n",
    "    mlp_nn = MLPClassifier()\n",
    "    # scaling\n",
    "    features = scaler_nn.fit_transform(features)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = mlp_nn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_nn = Pipeline([('nn', mlp_nn)])\n",
    "    # Try values of hidden_layer_sizes ranging from (30,) to (60,) by increments of 10.\n",
    "    param_grid_nn = {\n",
    "        'nn__hidden_layer_sizes': [(30,),(40,),(50,),(60,)],\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu']\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV with 5 fold cross validation to find the best hidden layer size and the best activation function.\n",
    "    grid_nn = GridSearchCV(pipe_nn, param_grid_nn, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_nn.fit(features, labels)\n",
    "    print(\"Best params: \", grid_nn.best_params_)\n",
    "    # Wrapping the GridSearchCV in a 5-fold cross_val_score.\n",
    "    pred_nn = cross_val_score(grid_nn, features, labels, cv=5)\n",
    "    # Prints the accuracy of your neural net\n",
    "    print(\"Accuracy of neural network with the best parameters and CV: \", pred_nn.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = cross_val_predict(grid_nn, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "    \n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)\n",
    "    proba = mlp_nn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Neural Network Classifier with SMOTE\n",
    "def neural_network_SMOTE(features):\n",
    "    scaler_nn = StandardScaler()\n",
    "    mlp_nn = MLPClassifier()\n",
    "    smt = SMOTE()\n",
    "    # scaling\n",
    "    features = scaler_nn.fit_transform(features)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = mlp_nn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_nn = Pipeline([('smt', smt), ('nn', mlp_nn)])\n",
    "    # Try values of hidden_layer_sizes ranging from (30,) to (60,) by increments of 10.\n",
    "    param_grid_nn = {\n",
    "        'nn__hidden_layer_sizes': [(30,),(40,),(50,),(60,)],\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'smt__k_neighbors': list(range(1, 18, 2))\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV with 5 fold cross validation to find the best hidden layer size and the best activation function.\n",
    "    grid_nn = GridSearchCV(pipe_nn, param_grid_nn, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_nn.fit(features, labels)\n",
    "    print(\"Best params: \", grid_nn.best_params_)\n",
    "    # Wrapping the GridSearchCV in a 5-fold cross_val_score.\n",
    "    pred_nn = cross_val_score(grid_nn, features, labels, cv=5)\n",
    "    # Prints the accuracy of your neural net\n",
    "    print(\"Accuracy of neural network with the best parameters and CV: \", pred_nn.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = cross_val_predict(grid_nn, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)\n",
    "    proba = mlp_nn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# using RandomForestClassifier\n",
    "# Ensemble Classifier with SMOTE\n",
    "def ensemble_SMOTE(features):\n",
    "    rf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "    rf.fit(feat_train, label_train) # train the model\n",
    "    label_predict = rf.predict(feat_test) # predict labels of test data\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple ensemble: \", accuracy*100)\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipe_ensemble = Pipeline([('smt', smt), ('rf', rf)])\n",
    "    # parameter-grid\n",
    "    params_rf = {'rf__max_depth': list(range(35,56)), \n",
    "                 'rf__min_samples_leaf': [8,10,12], \n",
    "                 'rf__max_features': ['sqrt','log2'],\n",
    "                 'smt__k_neighbors': list(range(1, 16, 2)),\n",
    "    }\n",
    "\n",
    "    # Using GridSearchCV with a 5-fold CV to tune the hyperparameters to get the best results.\n",
    "    grid_search_rf = GridSearchCV(pipe_ensemble, params_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "    grid_search_rf.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search_rf.best_params_)\n",
    "    # Wrapping the GridSearchCV in a cross_val_score with 5-fold CV to report the accuracy of the model.\n",
    "    pred_rf = sk.model_selection.cross_val_score(grid_search_rf, features, labels, cv=5)\n",
    "    print(\"Accuracy of ensemble with the best parameters and CV: \", pred_rf.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search_rf, features, labels, cv=5)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    rf.fit(feat_train, label_train)\n",
    "    proba = rf.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree, no SMOTE\n",
      "Accuracy of decision tree:  97.3\n",
      "Best params:  {'decision_tree__max_depth': 5, 'decision_tree__max_features': 10, 'decision_tree__min_samples_leaf': 15}\n",
      "Accuracy of decision tree with the best parameters and CV:  97.02027888027887\n",
      "Confusion matrix: \n",
      " [[4719   50]\n",
      " [  89  142]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      4769\n",
      "           1       0.74      0.61      0.67       231\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.86      0.80      0.83      5000\n",
      "weighted avg       0.97      0.97      0.97      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.8538322430845482\n",
      "Naive Bayes, no SMOTE\n",
      "Accuracy of simple Naive Bayes: 93.49987479949921\n",
      "Accuracy of naive bayes with the best parameters and CV:  93.22001742001743\n",
      "Accuracy of decision tree with the best parameters and CV:  93.22001742001743\n",
      "Confusion matrix: \n",
      " [[4504  265]\n",
      " [  60  171]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97      4769\n",
      "           1       0.39      0.74      0.51       231\n",
      "\n",
      "    accuracy                           0.94      5000\n",
      "   macro avg       0.69      0.84      0.74      5000\n",
      "weighted avg       0.96      0.94      0.94      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.940769350985689\n",
      "Nearest Neighbors, no SMOTE\n",
      "Accuracy of simple KNN:  95.6\n",
      "Best params:  {'knn__n_neighbors': 9, 'pca__n_components': 11}\n",
      "Accuracy of knn with the best parameters and CV:  96.8202587002587\n",
      "Confusion matrix: \n",
      " [[4738   31]\n",
      " [ 128  103]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4769\n",
      "           1       0.77      0.45      0.56       231\n",
      "\n",
      "    accuracy                           0.97      5000\n",
      "   macro avg       0.87      0.72      0.77      5000\n",
      "weighted avg       0.96      0.97      0.96      5000\n",
      "\n",
      "ROC AUC score, how good is this model?:  0.6777924136545288\n"
     ]
    }
   ],
   "source": [
    "# set of classifiers without SMOTE\n",
    "decision_tree_no_SMOTE(features)\n",
    "naive_bayes_no_SMOTE(features)\n",
    "svm_no_SMOTE(features)\n",
    "nearest_neighbors_no_SMOTE(features)\n",
    "neural_network_no_SMOTE(features)\n",
    "ensemble_no_SMOTE(features)\n",
    "\n",
    "# set of classifiers with SMOTE\n",
    "decision_tree_SMOTE(features)\n",
    "naive_bayes_SMOTE(features)\n",
    "svm_SMOTE(features)\n",
    "nearest_neighbors_SMOTE(features)\n",
    "neural_network_SMOTE(features)\n",
    "ensemble_SMOTE(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
