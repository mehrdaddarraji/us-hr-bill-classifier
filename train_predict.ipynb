{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import sklearn.naive_bayes\n",
    "import sklearn.model_selection\n",
    "import sklearn.tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.pipeline\n",
    "import sklearn.decomposition\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "# need to pip install import_ipynb\n",
    "import import_ipynb\n",
    "# need to pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.pipeline import Pipeline\n",
    "from data_preperation import features, labels\n",
    "\n",
    "# at this point, data should be clean \n",
    "print(features.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit and transform to all columns\n",
    "features = features.apply(le.fit_transform)\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "\n",
    "# fit\n",
    "enc.fit_transform(features)\n",
    "\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80%/20% split of the actual data\n",
    "features, labels = resample(features, labels, n_samples=5000)\n",
    "feat_train, feat_test, label_train, label_test = sk.model_selection.train_test_split(features, labels, test_size=0.2)\n",
    "print(label_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier without SMOTE\n",
    "def decision_tree_no_SMOTE(features):\n",
    "    print(\"Decision Tree, no SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of decision tree: \", accuracy*100)\n",
    "\n",
    "    # DOING CROSS VALIDATION \n",
    "    # outer loop for CV\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision tree\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10]}\n",
    "    \n",
    "    pipeline = Pipeline([('decision_tree', decision_tree)])\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # inner & outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "    # prints the accuracy of your decision tree\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    # running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Decision Tree classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier with SMOTE\n",
    "def decision_tree_SMOTE(features):\n",
    "    print(\"Decision Tree, SMOTE\")\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "    decision_tree.fit(feat_train, label_train) # train model\n",
    "\n",
    "    label_predict = decision_tree.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of decision tree: \", accuracy*100)\n",
    "\n",
    "    smt = SMOTE()\n",
    "    decision_tree = sk.tree.DecisionTreeClassifier(criterion='entropy') # make model\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(decision_tree, features, labels, cv=10) \n",
    "\n",
    "    # find the best parameters for decision tree\n",
    "    params = {\"decision_tree__max_depth\": [5,10,15,20],  \n",
    "              \"decision_tree__min_samples_leaf\": [5,10,15,20], \n",
    "              \"decision_tree__max_features\": [5,10],\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))\n",
    "             }\n",
    "\n",
    "    pipeline = Pipeline([('smt', smt), ('decision_tree', decision_tree)])\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # inner & outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Decision Tree classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    decision_tree.fit(feat_train, label_train)\n",
    "    proba = decision_tree.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier without SMOTE\n",
    "# simple with CV:\n",
    "def naive_bayes_no_SMOTE(features):\n",
    "    print(\"Naive Bayes, no SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    print(\"Accuracy of simple Naive Bayes:\", scores.mean()*100)\n",
    "\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "\n",
    "    pipeline = Pipeline([('naive_bayes', naive_bayes)])\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    \n",
    "    # outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "    # prints the accuracy of your naive bayes\n",
    "    print(\"Accuracy of naive bayes with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Naive Bayes classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "    \n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier with SMOTE\n",
    "def naive_bayes_SMOTE(features):\n",
    "    print(\"Naive Bayes, SMOTE\")\n",
    "    naive_bayes = sk.naive_bayes.GaussianNB()\n",
    "    \n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    print(\"Accuracy of simple Naive Bayes: \", scores.mean()*100)\n",
    "\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "    params = {\n",
    "              'smt__k_neighbors': list(range(1, 16, 2))\n",
    "            }\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('naive_bayes', naive_bayes)]) \n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=10)\n",
    "        \n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_search = GridSearchCV(pipeline, params, cv=5, scoring='accuracy')\n",
    "    \n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    \n",
    "    # outer loop\n",
    "    decision_acc = sk.model_selection.cross_val_score(naive_bayes, features, labels, cv=5)\n",
    "    # prints the accuracy of your naive bayes\n",
    "    print(\"Accuracy of naive bayes with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "\n",
    "    print(\"Accuracy of decision tree with the best parameters and CV: \", decision_acc.mean()*100)\n",
    "    \n",
    "    # Model Analysis: Confusion Matrix\n",
    "    labels_predict = sk.model_selection.cross_val_predict(naive_bayes, features, labels, cv=10)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a Naive Bayes classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    naive_bayes.fit(feat_train, label_train)\n",
    "    proba = naive_bayes.predict_proba(feat_test)\n",
    "    \n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Support Vector Machines(SVM) Classifier without SMOTE\n",
    "def svm_no_SMOTE(features):\n",
    "    print(\"SVM, no SMOTE\")\n",
    "    scaler_svm = StandardScaler()\n",
    "    # scaling\n",
    "    features = scaler_svm.fit_transform(features)\n",
    "    pca_redux_svm = PCA()\n",
    "    svm_obj = SVC(probability=True)\n",
    "    sm = SMOTE()\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train) # train the model\n",
    "    label_predict = svm_obj.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_svm = Pipeline([('pca', pca_redux_svm), ('svm', svm_obj)])\n",
    "    \n",
    "    # parameter-grid\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(3, 13)),\n",
    "        'svm__kernel': ['linear', 'rbf','poly']\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_svm = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_svm.fit(features, labels)\n",
    "\n",
    "    print(\"Best params: \", grid_svm.best_params_)\n",
    "\n",
    "    pred_svm = cross_val_score(grid_svm, features, labels, cv=5)\n",
    "    # prints the accuracy of your neural net\n",
    "    print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, pred_svm)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using an SVM classifier on this data.\n",
    "    report_svm = classification_report(labels, pred_svm)\n",
    "    print(\"\\nClassification report:\\n\", report_svm)\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)\n",
    "    proba = svm_obj.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Support Vector Machines(SVM) Classifier with SMOTE\n",
    "def svm_SMOTE(features):\n",
    "    print(\"SVM, SMOTE\")\n",
    "    scaler_svm = StandardScaler()\n",
    "    # scaling\n",
    "    features = scaler_svm.fit_transform(features)\n",
    "    pca_redux_svm = PCA()\n",
    "    svm_obj = SVC(probability=True)\n",
    "    sm = SMOTE()\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = svm_obj.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_svm = Pipeline([('smote', sm), ('pca', pca_redux_svm), ('svm', svm_obj)])\n",
    "\n",
    "    # parameter-grid\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(3, 13)),\n",
    "        'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'smote__k_neighbors': list(range(1, 10, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold \n",
    "    grid_svm = GridSearchCV(pipe_svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_svm.fit(features, labels)\n",
    "    print(\"Best params: \", grid_svm.best_params_)\n",
    "\n",
    "    pred_svm = cross_val_score(grid_svm, features, labels, cv=5)\n",
    "    # prints the accuracy of your neural net\n",
    "    print(\"Accuracy of svm with the best parameters and CV: \", pred_svm.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 10-fold CV for the outer loop.\n",
    "    pred_svm = cross_val_predict(grid_svm, features, labels, cv=10)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, pred_svm)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using an SVM classifier on this data.\n",
    "    report_svm = classification_report(labels, pred_svm)\n",
    "    print(\"\\nClassification report:\\n\", report_svm)\n",
    "\n",
    "    svm_obj.fit(feat_train, label_train)\n",
    "    proba = svm_obj.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest Neighbors Classifier without SMOTE\n",
    "def nearest_neighbors_no_SMOTE(features):\n",
    "    print(\"Nearest Neighbors, no SMOTE\")\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    # scaling\n",
    "    features = standard_scaler.fit_transform(features)\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier()\n",
    "    pipeline = Pipeline([('pca', pca), ('knn', knn)])\n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "\n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    # Prints the accuracy of your knn\n",
    "    print(\"Accuracy of knn with the best parameters and CV: \", scores.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a nearest neighbor classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Nearest Neighbors Classifier with SMOTE\n",
    "def nearest_neighbors_SMOTE(features):\n",
    "    print(\"Nearest Neighbors, SMOTE\")\n",
    "\n",
    "    standard_scaler = sk.preprocessing.StandardScaler()\n",
    "    # scaling\n",
    "    features = standard_scaler.fit_transform(features)\n",
    "    pca = sk.decomposition.PCA()\n",
    "    knn = sk.neighbors.KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "    knn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = knn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple KNN: \", accuracy*100)\n",
    "\n",
    "    knn = sk.neighbors.KNeighborsClassifier()\n",
    "    smt = SMOTE()\n",
    "    pipeline = Pipeline([('smt', smt), ('pca', pca), ('knn', knn)])\n",
    "    # inner loop\n",
    "    scores = sk.model_selection.cross_val_score(pipeline, features, labels, cv=5)\n",
    "    \n",
    "    param_grid = {\n",
    "        'pca__n_components': list(range(1, 14)),\n",
    "        'knn__n_neighbors': list(range(1, 26, 2)),\n",
    "        'smt__k_neighbors': list(range(1, 26, 2))\n",
    "    }\n",
    "\n",
    "    # creating a GridSearchCV for the inner CV loop with 5-fold\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "    grid_search.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "\n",
    "    # this does the nested loop\n",
    "    scores = sk.model_selection.cross_val_score(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    # Prints the accuracy of your knn\n",
    "    print(\"Accuracy of knn with the best parameters and CV: \", scores.mean()*100)\n",
    "\n",
    "    # Model Analysis: Confusion Matrix\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search, features, labels, cv=5, n_jobs=-1)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a nearest neighbor classifier on this data.\n",
    "    report = sklearn.metrics.classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    knn.fit(feat_train, label_train)\n",
    "    proba = knn.predict_proba(feat_test)\n",
    "\n",
    "    # Model Analysis: ROC Curve\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Neural Network Classifier without SMOTE\n",
    "def neural_network_no_SMOTE(features):\n",
    "    print(\"Neural network, no SMOTE\")\n",
    "    scaler_nn = StandardScaler()\n",
    "    mlp_nn = MLPClassifier()\n",
    "    # scaling\n",
    "    features = scaler_nn.fit_transform(features)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = mlp_nn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_nn = Pipeline([('nn', mlp_nn)])\n",
    "    # Try values of hidden_layer_sizes ranging from (30,) to (60,) by increments of 10.\n",
    "    param_grid_nn = {\n",
    "        'nn__hidden_layer_sizes': [(30,),(40,),(50,),(60,)],\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu']\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV with 5 fold cross validation to find the best hidden layer size and the best activation function.\n",
    "    grid_nn = GridSearchCV(pipe_nn, param_grid_nn, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_nn.fit(features, labels)\n",
    "    print(\"Best params: \", grid_nn.best_params_)\n",
    "    # Wrapping the GridSearchCV in a 5-fold cross_val_score.\n",
    "    pred_nn = cross_val_score(grid_nn, features, labels, cv=5)\n",
    "    # Prints the accuracy of your neural net\n",
    "    print(\"Accuracy of neural network with the best parameters and CV: \", pred_nn.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = cross_val_predict(grid_nn, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "    \n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)\n",
    "    proba = mlp_nn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Neural Network Classifier with SMOTE\n",
    "def neural_network_SMOTE(features):\n",
    "    print(\"Neural network, SMOTE\")\n",
    "    scaler_nn = StandardScaler()\n",
    "    mlp_nn = MLPClassifier()\n",
    "    smt = SMOTE()\n",
    "    # scaling\n",
    "    features = scaler_nn.fit_transform(features)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)  # train the model\n",
    "    label_predict = mlp_nn.predict(feat_test) # predict labels of test data\n",
    "\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple neural network: \", accuracy*100)\n",
    "\n",
    "    pipe_nn = Pipeline([('smt', smt), ('nn', mlp_nn)])\n",
    "    # Try values of hidden_layer_sizes ranging from (30,) to (60,) by increments of 10.\n",
    "    param_grid_nn = {\n",
    "        'nn__hidden_layer_sizes': [(30,),(40,),(50,),(60,)],\n",
    "        'nn__activation': ['logistic', 'tanh', 'relu'],\n",
    "        'smt__k_neighbors': list(range(1, 18, 2))\n",
    "    }\n",
    "\n",
    "    # Use GridSearchCV with 5 fold cross validation to find the best hidden layer size and the best activation function.\n",
    "    grid_nn = GridSearchCV(pipe_nn, param_grid_nn, cv=5, scoring='accuracy')\n",
    "\n",
    "    grid_nn.fit(features, labels)\n",
    "    print(\"Best params: \", grid_nn.best_params_)\n",
    "    # Wrapping the GridSearchCV in a 5-fold cross_val_score.\n",
    "    pred_nn = cross_val_score(grid_nn, features, labels, cv=5)\n",
    "    # Prints the accuracy of your neural net\n",
    "    print(\"Accuracy of neural network with the best parameters and CV: \", pred_nn.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = cross_val_predict(grid_nn, features, labels, cv=5)\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    mlp_nn.fit(feat_train, label_train)\n",
    "    proba = mlp_nn.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# using RandomForestClassifier\n",
    "# Ensemble Classifier with SMOTE\n",
    "def ensemble_SMOTE(features):\n",
    "    print(\"Ensemble, SMOTE\")\n",
    "    rf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "    rf.fit(feat_train, label_train) # train the model\n",
    "    label_predict = rf.predict(feat_test) # predict labels of test data\n",
    "    accuracy = sk.metrics.accuracy_score(label_test, label_predict)\n",
    "    print(\"Accuracy of simple ensemble: \", accuracy*100)\n",
    "\n",
    "    smt = SMOTE()\n",
    "    pipe_ensemble = Pipeline([('smt', smt), ('rf', rf)])\n",
    "    # parameter-grid\n",
    "    params_rf = {'rf__max_depth': list(range(35,56)), \n",
    "                 'rf__min_samples_leaf': [8,10,12], \n",
    "                 'rf__max_features': ['sqrt','log2'],\n",
    "                 'smt__k_neighbors': list(range(1, 16, 2)),\n",
    "    }\n",
    "\n",
    "    # Using GridSearchCV with a 5-fold CV to tune the hyperparameters to get the best results.\n",
    "    grid_search_rf = GridSearchCV(pipe_ensemble, params_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "    grid_search_rf.fit(features, labels)\n",
    "    print(\"Best params: \", grid_search_rf.best_params_)\n",
    "    # Wrapping the GridSearchCV in a cross_val_score with 5-fold CV to report the accuracy of the model.\n",
    "    pred_rf = sk.model_selection.cross_val_score(grid_search_rf, features, labels, cv=5)\n",
    "    print(\"Accuracy of ensemble with the best parameters and CV: \", pred_rf.mean()*100)\n",
    "\n",
    "    # CONFUSION MATRIX EVALUATION\n",
    "    # Running a cross_val_predict with a 5-fold CV for the outer loop.\n",
    "    labels_predict = sk.model_selection.cross_val_predict(grid_search_rf, features, labels, cv=5)\n",
    "\n",
    "    conf_mat = sklearn.metrics.confusion_matrix(labels, labels_predict)\n",
    "    print(\"Confusion matrix: \\n\", conf_mat)\n",
    "\n",
    "    # CLASSIFICATION REPORT of using a neural network classifier on this data.\n",
    "    report = classification_report(labels, labels_predict)\n",
    "    print(\"\\nClassification report:\\n\", report)\n",
    "\n",
    "    rf.fit(feat_train, label_train)\n",
    "    proba = rf.predict_proba(feat_test)\n",
    "\n",
    "    # ROC CURVE EVALUATION\n",
    "    roc = sk.metrics.roc_curve(label_test, proba[:, 1])\n",
    "    roc_auc = sk.metrics.roc_auc_score(label_test, proba[:, 1])\n",
    "\n",
    "    print(\"ROC AUC score, how good is this model?: \", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of classifiers without SMOTE\n",
    "decision_tree_no_SMOTE(features)\n",
    "naive_bayes_no_SMOTE(features)\n",
    "svm_no_SMOTE(features)\n",
    "nearest_neighbors_no_SMOTE(features)\n",
    "neural_network_no_SMOTE(features)\n",
    "ensemble_no_SMOTE(features)\n",
    "\n",
    "# set of classifiers with SMOTE\n",
    "decision_tree_SMOTE(features)\n",
    "naive_bayes_SMOTE(features)\n",
    "svm_SMOTE(features)\n",
    "nearest_neighbors_SMOTE(features)\n",
    "neural_network_SMOTE(features)\n",
    "ensemble_SMOTE(features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
